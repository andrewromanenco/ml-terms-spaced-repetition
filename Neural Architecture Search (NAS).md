
A technique for automatically designing the architecture of a
[[neural network|neural network]]. NAS algorithms can reduce the amount
of time and resources required to train a neural network.

NAS typically uses:

<ul>
<li>A search space, which is a set of possible architectures.</li>
<li>A fitness function, which is a measure of how well a particular
architecture performs on a given task.</li>
</ul>

NAS algorithms often start with a small set of possible architectures and
gradually expand the search space as the algorithm learns more about what
architectures are effective. The fitness function is typically based on the
performance of the architecture on a training set, and the algorithm is
typically trained using a
[[reinforcement learning (RL)|reinforcement learning]] technique.

NAS algorithms have proven effective in finding high-performing
architectures for a variety of tasks, including image
[[classification model|classification]], text classification,
and machine translation.

<a class="glossary-anchor" name="neural-network"></a>
