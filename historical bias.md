#fairness

A type of [[bias (math) or bias term|bias]] that already exists in the world and has
made its way into a dataset. These biases have a tendency to reflect existing
cultural stereotypes, demographic inequalities, and prejudices against certain
social groups.

For example, consider a [[classification model|classification model]] that
predicts whether or not a loan applicant will default on their loan, which was
trained on historical loan-default data from the 1980s from local banks in two
different communities. If past applicants from Community A were six times more
likely to default on their loans than applicants from Community B, the model
might learn a historical bias resulting in the model being less likely to
approve loans in Community A, even if the historical conditions that resulted
in that community&#39;s higher default rates were no longer relevant.

