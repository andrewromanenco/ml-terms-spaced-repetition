
[[normalization|Normalizing]] the input or output of the
[[activation function|activation functions]] in a
[[hidden layer|hidden layer]]. Batch normalization can
provide the following benefits:

<ul>
<li>Make [[neural network|neural networks]] more stable by protecting
against [[outliers|outlier]] weights.</li>
<li>Enable higher [[learning rate|learning rates]], which can
speed training.</li>
<li>Reduce [[overfitting|overfitting]].</li>
</ul>

