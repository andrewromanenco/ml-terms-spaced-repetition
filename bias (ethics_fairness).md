#fairness, #fundamentals


1. Stereotyping, prejudice or favoritism towards some things, people,
or groups over others. These biases can affect collection and
interpretation of data, the design of a system, and how users interact
with a system. Forms of this type of bias include:


<ul>
<li>[[automation bias|automation bias]]</li>
<li>[[confirmation bias|confirmation bias]]</li>
<li>[[confirmation bias|experimenter&#39;s bias]]</li>
<li>[[group attribution bias|group attribution bias]]</li>
<li>[[implicit bias|implicit bias]]</li>
<li>[[in-group bias|in-group bias]]</li>
<li>[[out-group homogeneity bias|out-group homogeneity bias]]</li>
</ul>


2. Systematic error introduced by a sampling or reporting procedure.
Forms of this type of bias include:


<ul>
<li>[[selection bias|coverage bias]]</li>
<li>[[selection bias|non-response bias]]</li>
<li>[[participation bias|participation bias]]</li>
<li>[[reporting bias|reporting bias]]</li>
<li>[[selection bias|sampling bias]]</li>
<li>[[selection bias|selection bias]]</li>
</ul>

Not to be confused with the [[bias (math) or bias term|bias term]] in machine learning models
or [[prediction bias|prediction bias]].

