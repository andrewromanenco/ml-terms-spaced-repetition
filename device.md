#TensorFlow, #GoogleCloud

An overloaded term with the following two possible definitions:

<ol>
<li>A category of hardware that can run a TensorFlow session, including
CPUs, GPUs, and [[TPU|TPUs]].</li>
<li>When training an ML model on [[accelerator chip|accelerator chips]]
(GPUs or TPUs), the part of the system that actually manipulates
[[Tensor|tensors]] and [[embedding layer|embeddings]].
The device runs on accelerator chips. In contrast, the [[host|host]]
typically runs on a CPU.</li>
</ol>

