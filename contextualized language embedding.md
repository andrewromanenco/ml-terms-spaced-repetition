#language, #generativeAI

An [[embedding vector|embedding]] that comes close to &quot;understanding&quot; words
and phrases in ways that native human speakers can. Contextualized language
embeddings can understand complex syntax, semantics, and context.

For example, consider embeddings of the English word <em>cow</em>. Older embeddings
such as <a href="https://wikipedia.org/wiki/Word2vec">word2vec</a> can represent English
words such that the distance in the [[embedding space|embedding space]]
from <em>cow</em> to <em>bull</em> is similar to the distance from <em>ewe</em> (female sheep) to
<em>ram</em> (male sheep) or from <em>female</em> to <em>male</em>. Contextualized language
embeddings can go a step further by recognizing that English speakers sometimes
casually use the word <em>cow</em> to mean either cow or bull.

