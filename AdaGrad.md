
A sophisticated gradient descent algorithm that rescales the
gradients of each [[parameter|parameter]], effectively giving each parameter
an independent [[learning rate|learning rate]]. For a full explanation, see
<a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf"
target="T">this AdaGrad paper</a>.

