#fairness

A [[fairness metric|fairness metric]] that checks whether a classifier
produces the same result for one individual as it does for another individual
who is identical to the first, except with respect to one or more
[[sensitive attribute|sensitive attributes]]. Evaluating a classifier for
counterfactual fairness is one method for surfacing potential sources of
bias in a model.

See
<a href="https://papers.nips.cc/paper/2017/file/1271a7029c9df08643b631b02cf9e116-Paper.pdf"
target="T">&quot;When Worlds Collide: Integrating Different Counterfactual
Assumptions in Fairness&quot;</a> for a more detailed discussion of counterfactual
fairness.

