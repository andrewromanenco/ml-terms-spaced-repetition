
In machine learning, an anonymization approach to protect any sensitive data
(for example, an individual&#39;s personal information) included in a model&#39;s
[[training set|training set]] from being exposed. This approach ensures
that the [[model|model]] doesn&#39;t learn or remember much about a specific
individual. This is accomplished by sampling and adding noise during model
training to obscure individual data points, mitigating the risk of exposing
sensitive training data.

Differential privacy is also used outside of machine learning. For example,
data scientists sometimes use differential privacy to protect individual
privacy when computing product usage statistics for different demographics.

